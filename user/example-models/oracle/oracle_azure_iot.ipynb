{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from oracle_w_fuzzy import load_data\n",
                "import pandas as pd\n",
                "import numpy as np"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from h1st.model.predictive_model import PredictiveModel\n",
                "class RuleModel(PredictiveModel):\n",
                "    # 98 percentile\n",
                "    daily_thresholds = {\n",
                "        \"volt\": 188.83,  # >\n",
                "        \"rotate\": 373.05,  # <\n",
                "        \"vibration\": 49.38,  # >\n",
                "    }\n",
                "\n",
                "    def predict_pointwise(self, input_data):\n",
                "        daily_average = np.average(\n",
                "            input_data.reshape((-1, 4)), axis=0\n",
                "        )\n",
                "        volt_val = daily_average[0]\n",
                "        rotate_val = daily_average[1]\n",
                "        vibration_val = daily_average[3]\n",
                "\n",
                "        pred = {\"comp1\": 0, \"comp2\": 0, \"comp4\": 0}\n",
                "        pred['comp1'] = 1 if volt_val > self.daily_thresholds[\"volt\"] else 0\n",
                "        pred['comp2'] = 1 if rotate_val < self.daily_thresholds[\"rotate\"] else 0\n",
                "        pred['comp4'] = 1 if vibration_val > self.daily_thresholds[\"vibration\"] else 0\n",
                "        return pred\n",
                "\n",
                "    def predict(self, input_data):\n",
                "        df = input_data['x']\n",
                "        return {'predictions': pd.DataFrame(\n",
                "            map(self.predict_pointwise, df.values), \n",
                "        )}  "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "from h1st.model.fuzzy import (\n",
                "    FuzzyVariables,\n",
                "    FuzzyMembership as fm,\n",
                "    FuzzyRules,\n",
                "    FuzzyModel,\n",
                "    FuzzyModeler\n",
                ")\n",
                "\n",
                "def get_meta_data(data):\n",
                "    res = {}\n",
                "    for k, v in dict(data.describe().loc['max']).items():\n",
                "        res[k] = {'max': v}\n",
                "    for k, v in dict(data.describe().loc['min']).items():\n",
                "        res[k].update({'min': v})    \n",
                "    return res\n",
                "\n",
                "def create_fuzzy_model(data):\n",
                "    meta_data = get_meta_data(data) # df_model3_daily\n",
                "    fuzzy_vars = FuzzyVariables()\n",
                "    fuzzy_vars.add(\n",
                "        var_name='volt',\n",
                "        var_type='antecedent',\n",
                "        var_range=np.arange(\n",
                "            meta_data['volt']['min'], \n",
                "            meta_data['volt']['max'], \n",
                "            0.1\n",
                "        ),\n",
                "        membership_funcs=[('high', fm.SIGMOID, [188.83, 0.25]), # 180\n",
                "                        ('low', fm.SIGMOID, [188.83, -0.25])]\n",
                "    )\n",
                "    fuzzy_vars.add(\n",
                "        var_name='rotate',\n",
                "        var_type='antecedent',\n",
                "        var_range=np.arange(\n",
                "            meta_data['rotate']['min'], \n",
                "            meta_data['rotate']['max'], \n",
                "            0.1\n",
                "        ),\n",
                "        membership_funcs=[('high', fm.SIGMOID, [373.05, 0.06]), # 400\n",
                "                        ('low', fm.SIGMOID, [373.05, -0.15])]\n",
                "    )\n",
                "    fuzzy_vars.add(\n",
                "        var_name='vibration',\n",
                "        var_type='antecedent',\n",
                "        var_range=np.arange(\n",
                "            meta_data['vibration']['min'], \n",
                "            meta_data['vibration']['max'], \n",
                "            0.1\n",
                "        ),\n",
                "        membership_funcs=[('high', fm.SIGMOID, [49.38, 0.5]), # 44 ?\n",
                "                        ('low', fm.SIGMOID, [49.38, -0.5])]\n",
                "    )\n",
                "    fuzzy_vars.add(\n",
                "        var_name='comp1',\n",
                "        var_type='consequent',\n",
                "        var_range=np.arange(0, 1+1e-5, 0.1),\n",
                "        membership_funcs=[('false', fm.GAUSSIAN, [0, 0.4]),\n",
                "                        ('true', fm.GAUSSIAN, [1, 0.4])]\n",
                "    )\n",
                "    fuzzy_vars.add(\n",
                "        var_name='comp2',\n",
                "        var_type='consequent',\n",
                "        var_range=np.arange(0, 1+1e-5, 0.1),\n",
                "        membership_funcs=[('false', fm.GAUSSIAN, [0, 0.4]),\n",
                "                        ('true', fm.GAUSSIAN, [1, 0.4])]\n",
                "    )\n",
                "    fuzzy_vars.add(\n",
                "        var_name='comp4',\n",
                "        var_type='consequent',\n",
                "        var_range=np.arange(0, 1+1e-5, 0.1),\n",
                "        membership_funcs=[('false', fm.GAUSSIAN, [0, 0.4]),\n",
                "                        ('true', fm.GAUSSIAN, [1, 0.4])]\n",
                "    )\n",
                "\n",
                "    fuzzy_rule = FuzzyRules()\n",
                "    fuzzy_rule.add(\n",
                "        'rule1',\n",
                "        if_term=fuzzy_vars.get('volt')['high']&fuzzy_vars.get('rotate')['high']&fuzzy_vars.get('vibration')['low'],\n",
                "        then_term=fuzzy_vars.get('comp1')['true']\n",
                "    )\n",
                "    fuzzy_rule.add(\n",
                "        'rule2',\n",
                "        if_term=fuzzy_vars.get('rotate')['low']&fuzzy_vars.get('volt')['low']&fuzzy_vars.get('vibration')['low'],\n",
                "        then_term=fuzzy_vars.get('comp2')['true']\n",
                "    )\n",
                "    fuzzy_rule.add(\n",
                "        'rule3',\n",
                "        if_term=fuzzy_vars.get('vibration')['high']&fuzzy_vars.get('volt')['low']&fuzzy_vars.get('rotate')['high'],\n",
                "        then_term=fuzzy_vars.get('comp4')['true']\n",
                "    )\n",
                "    fuzzy_rule.add(\n",
                "        'rule4',\n",
                "        if_term=fuzzy_vars.get('volt')['low'],\n",
                "        then_term=fuzzy_vars.get('comp1')['false']\n",
                "    )\n",
                "    fuzzy_rule.add(\n",
                "        'rule5',\n",
                "        if_term=fuzzy_vars.get('rotate')['high'],\n",
                "        then_term=fuzzy_vars.get('comp2')['false']\n",
                "    )\n",
                "    fuzzy_rule.add(\n",
                "        'rule6',\n",
                "        if_term=fuzzy_vars.get('vibration')['low'],\n",
                "        then_term=fuzzy_vars.get('comp4')['false']\n",
                "    )\n",
                "\n",
                "    class CustomFuzzyModel(FuzzyModel):\n",
                "        def process_rules_pointwise(self, input_data: dict) -> dict:\n",
                "            if self.rule_engine is None:\n",
                "                raise ValueError(\n",
                "                    (\n",
                "                        \"Property rule_engine is None. Please load your rule_engine \"\n",
                "                        \"to run this method.\"\n",
                "                    )\n",
                "                )\n",
                "\n",
                "            input_data = np.array(list(input_data.values()))\n",
                "            daily_average = np.average(\n",
                "                input_data.reshape((-1, 4)), axis=0\n",
                "            )\n",
                "            input_data = {\n",
                "                \"volt\": daily_average[0],\n",
                "                \"rotate\": daily_average[1],\n",
                "                \"vibration\": daily_average[3]\n",
                "            } \n",
                "            for key, value in input_data.items():\n",
                "                self.rule_engine.input[key] = value\n",
                "            self.rule_engine.compute()\n",
                "\n",
                "            outputs = {}\n",
                "            for cls in self.rule_engine.ctrl.consequents:\n",
                "                outputs[cls.label] = round(self.rule_engine.output[cls.label], 5)\n",
                "            return outputs\n",
                "\n",
                "    modeler = FuzzyModeler(model_class=CustomFuzzyModel)\n",
                "    teacher = modeler.build_model(fuzzy_vars, fuzzy_rule)\n",
                "    return teacher"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# you can download the data from kaggle using the following link.\n",
                "# https://www.kaggle.com/datasets/arnabbiswas1/microsoft-azure-predictive-maintenance\n",
                "\n",
                "dir_path = '/Users/aitomatic/Desktop/dataset/azure_iot'\n",
                "path = f'{dir_path}/'\n",
                "telemetry_url = 'PdM_telemetry.csv'\n",
                "df = pd.read_csv(path + 'PdM_telemetry.csv')\n",
                "df.loc[:, 'datetime'] = pd.to_datetime(df['datetime'])\n",
                "df.loc[:, 'datetime'] = df['datetime'] - pd.Timedelta(hours=6)\n",
                "df_machines = pd.read_csv(path + 'PdM_machines.csv')\n",
                "df = df.join(df_machines.set_index('machineID'), on='machineID')\n",
                "df.loc[:, 'date'] = df['datetime'].dt.date\n",
                "df_failures = pd.read_csv(path + 'PdM_failures.csv')\n",
                "df_failures.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for model_type in ['model1', 'model2', 'model3', 'model4']:\n",
                "    id_list = df[df.model == model_type].machineID.unique()\n",
                "    print(f'{model_type} failure records:', df_failures[df_failures.machineID.isin(id_list)].shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import datetime\n",
                "\n",
                "df_model3 = df[df.model=='model3']\n",
                "df_model3 = df_model3[df_model3.date != datetime.datetime(2016, 1, 1).date()]\n",
                "df_model3.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from datetime import timedelta\n",
                "\n",
                "df_model3_failures = df_failures[df_failures.machineID.isin(df_model3.machineID.unique())]\n",
                "df_model3_failures.shape\n",
                "\n",
                "\n",
                "df_model3_failures['datetime'] = pd.to_datetime(df_model3_failures['datetime'])\n",
                "df_model3_failures['date'] = df_model3_failures['datetime'].apply(lambda x: x.date())\n",
                "df_model3_failures['date_1'] = df_model3_failures['date'] - timedelta(days=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_model3_failures.failure.value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_model3_daily = df_model3.groupby(['date', 'machineID']).agg('mean')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# We will use these values as threshold value of boolean rule (98 percentile)\n",
                "percentile = 0.96\n",
                "print('volt:', df_model3_daily['volt'].quantile(percentile))\n",
                "print('rotate:', df_model3_daily['rotate'].quantile(1-percentile))\n",
                "print('vibration:', df_model3_daily['vibration'].quantile(percentile))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_model3.machineID.nunique()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "keys = ['machineID', 'date']\n",
                "features = ['volt', 'rotate', 'pressure', 'vibration']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "column_values = []\n",
                "for idx in range(24):\n",
                "    column_values.extend([f'{feature}_{idx}' for feature in features])\n",
                "print(column_values)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def preprocess_data(list_of_daily_data, features):\n",
                "    x_train_list = []\n",
                "    y_train_list = []\n",
                "    for idx, df_daily_one in list_of_daily_data:\n",
                "        mid = idx[0]\n",
                "        date = idx[1]\n",
                "\n",
                "        if df_daily_one.shape[0] != 24:\n",
                "            continue\n",
                "\n",
                "        df_filtered_f = df_model3_failures[\n",
                "            (df_model3_failures.date_1==date)&(df_model3_failures.machineID==mid)]\n",
                "        y_label = {\"comp1\": 0, \"comp2\": 0, \"comp4\": 0}\n",
                "        if df_filtered_f.shape[0] >= 1:\n",
                "            for i in range(df_filtered_f.shape[0]):\n",
                "                y_label.update({df_filtered_f['failure'].iloc[i]: 1})\n",
                "        x_train_list.append(np.concatenate(df_daily_one[features].values).tolist())\n",
                "        y_train_list.append(y_label)\n",
                "    return x_train_list, y_train_list"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.utils import resample\n",
                "\n",
                "def handle_data_imbalance(df_x, df_y):\n",
                "    df_train_y_normal = df_y[df_y.sum(axis=1) == 0]\n",
                "    df_train_y_normal_resampled = resample(df_train_y_normal,\n",
                "                replace=True,\n",
                "                n_samples=100,\n",
                "                random_state=42)\n",
                "    df_train_x_normal_resampled = df_x.filter(items = df_train_y_normal_resampled.index, axis=0)\n",
                "    assert all(df_train_y_normal_resampled.head().index == df_train_x_normal_resampled.head().index)\n",
                "\n",
                "    df_train_y_abnormal = df_y[df_y.sum(axis=1) != 0]\n",
                "    df_train_y_abnormal_resampled = resample(df_train_y_abnormal,\n",
                "                replace=True,\n",
                "                n_samples=600,\n",
                "                random_state=42)\n",
                "    df_train_y_abnormal_resampled.shape\n",
                "    df_train_x_abnormal_resampled = df_x.filter(items = df_train_y_abnormal_resampled.index, axis=0)\n",
                "    df_train_x_abnormal_resampled.shape\n",
                "    assert all(df_train_y_abnormal_resampled.head().index == df_train_x_abnormal_resampled.head().index)\n",
                "\n",
                "    df_train_y_final = pd.concat([df_train_y_normal_resampled, df_train_y_abnormal_resampled], axis=0)\n",
                "    df_train_x_final = pd.concat([df_train_x_normal_resampled, df_train_x_abnormal_resampled], axis=0)\n",
                "\n",
                "    return df_train_x_final, df_train_y_final\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from collections import defaultdict\n",
                "from sklearn.model_selection import KFold\n",
                "from h1st.model.oracle import OracleModeler\n",
                "from h1st.model.oracle.ensemble import MLPEnsembleModeler\n",
                "\n",
                "# prepare cross validation\n",
                "kfold = KFold(n_splits=5, shuffle=True, random_state=3)\n",
                "\n",
                "all_metrics = defaultdict(lambda: defaultdict(list))\n",
                "all_index = defaultdict(lambda: defaultdict(list))\n",
                "\n",
                "# 1. build rule-based model\n",
                "bool_teacher = RuleModel()\n",
                "fuzzy_teacher = create_fuzzy_model(df_model3_daily)\n",
                "fuzzy_thresholds = {'comp1': 0.46, 'comp2': 0.48, 'comp4': 0.46}\n",
                "\n",
                "for no, m_ids in enumerate(kfold.split(df_model3.machineID.unique())):\n",
                "    train_id, test_id = m_ids\n",
                "    df_train = df_model3[df_model3.machineID.isin(train_id)]\n",
                "    df_test = df_model3[df_model3.machineID.isin(test_id)]\n",
                "\n",
                "    temp_gb = df_train.groupby(keys)\n",
                "    list_of_train_daily = [item for item in temp_gb]\n",
                "\n",
                "    temp_gb = df_test.groupby(keys)\n",
                "    list_of_test_daily = [item for item in temp_gb]\n",
                "\n",
                "    # print(len(train_id), len(test_id),df_train.shape, df_test.shape)\n",
                "    # print(f'number of data points in train dataset: {len(list_of_train_daily)}')\n",
                "    # print(f'number of data points in test dataset: {len(list_of_test_daily)}')\n",
                "\n",
                "    \n",
                "    x_train_list, y_train_list = preprocess_data(list_of_train_daily, features)\n",
                "    x_test_list, y_test_list = preprocess_data(list_of_test_daily, features)\n",
                "\n",
                "    df_train_x = pd.DataFrame(x_train_list, columns=column_values)\n",
                "    df_train_y = pd.DataFrame(y_train_list)\n",
                "    df_test_x = pd.DataFrame(x_test_list, columns=column_values)\n",
                "    df_test_y = pd.DataFrame(y_test_list)\n",
                "\n",
                "    df_train_x_final, df_train_y_final = handle_data_imbalance(df_train_x, df_train_y)\n",
                "    # print(df_train_x.shape, df_train_y.shape, df_test_x.shape, df_test_y.shape)\n",
                "    # print(no, df_train_x_final.shape, df_train_y_final.shape)   \n",
                "    input_data = {\n",
                "        \"unlabeled_data\": df_train_x_final,\n",
                "        \"labeled_data\": {\n",
                "            \"x_train\": df_train_x_final.reset_index(drop=True),\n",
                "            \"y_train\": df_train_y_final.reset_index(drop=True),\n",
                "            \"x_test\": df_test_x,\n",
                "            \"y_test\": df_test_y,\n",
                "        },\n",
                "    }\n",
                "\n",
                "    # 3. build oracle\n",
                "    # 3.1 bool\n",
                "    modeler = OracleModeler()\n",
                "    oracle_with_bool = modeler.build_model(\n",
                "        data=input_data,\n",
                "        teacher=bool_teacher)\n",
                "\n",
                "    # 3.2 fuzzy\n",
                "    oracle_with_fuzzy = modeler.build_model(\n",
                "        data=input_data,\n",
                "        teacher=fuzzy_teacher,\n",
                "        fuzzy_thresholds=fuzzy_thresholds)\n",
                "\n",
                "    # 3.3 bool + ml_ensemble\n",
                "    oracle_with_bool_ml = modeler.build_model(\n",
                "        data=input_data, \n",
                "        teacher=bool_teacher,\n",
                "        ensembler_modeler=MLPEnsembleModeler())\n",
                "\n",
                "    # 3.4 fuzzy + ml_ensemble\n",
                "    oracle_with_fuzzy_ml = modeler.build_model(\n",
                "        data=input_data, \n",
                "        teacher=fuzzy_teacher,\n",
                "        fuzzy_thresholds=fuzzy_thresholds,\n",
                "        ensembler_modeler=MLPEnsembleModeler()) \n",
                "\n",
                "    # 3.5 bool + ml_ensemble + x\n",
                "    oracle_with_bool_ml_x = modeler.build_model(\n",
                "        data=input_data, \n",
                "        teacher=bool_teacher,\n",
                "        ensembler_modeler=MLPEnsembleModeler(),\n",
                "        inject_x_in_ensembler=True)\n",
                "\n",
                "    # 3.6 fuzzy + ml_ensemble + x\n",
                "    oracle_with_fuzzy_ml_x = modeler.build_model(\n",
                "        data=input_data, \n",
                "        teacher=fuzzy_teacher,\n",
                "        fuzzy_thresholds=fuzzy_thresholds,\n",
                "        ensembler_modeler=MLPEnsembleModeler(),\n",
                "        inject_x_in_ensembler=True) \n",
                "\n",
                "    model_map = {\n",
                "        \"oracle_with_bool\": oracle_with_bool,\n",
                "        \"oracle_with_fuzzy\": oracle_with_fuzzy,\n",
                "        \"oracle_with_bool_ml\": oracle_with_bool_ml,\n",
                "        \"oracle_with_fuzzy_ml\": oracle_with_fuzzy_ml,\n",
                "        \"oracle_with_bool_ml_x\": oracle_with_bool_ml_x,\n",
                "        \"oracle_with_fuzzy_ml_x\": oracle_with_fuzzy_ml_x,        \n",
                "    }\n",
                "\n",
                "    # 4. collect evaluation results\n",
                "    for name, oracle in model_map.items():\n",
                "        for metrics in [\"f1_score\", 'precision', 'recall']:\n",
                "            for label in ['comp1', 'comp2', 'comp4']:\n",
                "                temp = oracle.metrics[metrics][label]\n",
                "                s1, s2 = temp.pop('students')\n",
                "                temp.update({'student1': s1, 'student2': s2})\n",
                "                all_metrics[metrics][name].append({label: temp})\n",
                "                # all_index[metrics][name].append(f'{label}_{name}_{no}')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_avg_metrics = []\n",
                "oracle_names = []\n",
                "for metrics_type in ['f1_score', 'precision', 'recall']:\n",
                "    for oracle_name, metrics in all_metrics[metrics_type].items():\n",
                "\n",
                "        temp = defaultdict(list)\n",
                "        for m in metrics:\n",
                "            for label, met in m.items():\n",
                "                temp[label].append(met)\n",
                "\n",
                "        for label in temp:\n",
                "            df_metrics = pd.DataFrame(temp[label])\n",
                "            # print(metrics_type, oracle_name, df_metrics.mean().values)\n",
                "            all_avg_metrics.append(\n",
                "                [metrics_type, label] + list(df_metrics.mean().values)\n",
                "            )\n",
                "            oracle_names.append(f'{label}_{oracle_name}')\n",
                "\n",
                "final_metrics = pd.DataFrame(\n",
                "    all_avg_metrics,\n",
                "    columns=['metrics_type', 'label', 'teacher', 'ensemblers', 'student1', 'student2'],\n",
                "    index=oracle_names\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "final_metrics[final_metrics.label=='comp1']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "final_metrics[final_metrics.label=='comp1'].to_csv('azure_comp1.csv')\n",
                "final_metrics[final_metrics.label=='comp2'].to_csv('azure_comp2.csv')\n",
                "final_metrics[final_metrics.label=='comp4'].to_csv('azure_comp4.csv')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.9.12 ('h1st_fuzzy')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.12"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "650c0317428e71d2b7b924a16bfe592f0574d896a2da53bfdf150aa01abab0ba"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
